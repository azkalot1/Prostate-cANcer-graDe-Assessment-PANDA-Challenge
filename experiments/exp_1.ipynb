{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skolchenko/.local/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torchvision/_C.so'>\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pytorch_metric_learning import losses, miners, samplers, trainers, testers\n",
    "from pytorch_metric_learning.utils import common_functions\n",
    "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from panda_challenge.train_utils import QWKCallback\n",
    "from panda_challenge.utils import tile\n",
    "from panda_challenge.dataset import MetricLearningAndClassifcationDatasetMultiCrop\n",
    "import umap\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from catalyst.contrib.nn.modules import GlobalMaxPool2d, Flatten, Lambda\n",
    "import timm\n",
    "from catalyst import dl\n",
    "from catalyst.dl import utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import PIL\n",
    "import gc\n",
    "import pickle\n",
    "from catalyst.contrib.nn.optimizers import RAdam, Lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrunkMultiCropModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 model_name='resnet34',\n",
    "                 num_classes=6,\n",
    "                 embeddings_size=64,\n",
    "                     **kwargs):\n",
    "        super().__init__()\n",
    "        m = timm.create_model(\n",
    "            model_name,\n",
    "            **kwargs)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])\n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.embedder = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(nc, nc//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(nc//4, embedding_size))  \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(nc, nc//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(nc//4, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shape = x[0].shape\n",
    "        n = len(x[0])\n",
    "        x = x.view(-1, shape[1], shape[2], shape[3])\n",
    "        # x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        # should be: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        # concatenate the output for tiles into a single map\n",
    "        x = x.view(-1, n, shape[1], shape[2], shape[3])\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        x = x.view(-1, shape[1], shape[2]*n, shape[3])\n",
    "        x = self.pool(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x_cls = self.classifier(x)\n",
    "        x_embedding = self.embedder(x)\n",
    "        # should be: bs x C x N*4 x 4\n",
    "        return x_cls, x_embedding\n",
    "    \n",
    "    \n",
    "    \n",
    "class PickleMetricLearningAndClassifcationDatasetMultiCrop(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_df,\n",
    "        transforms_json,\n",
    "        image_dir,\n",
    "        mean=np.array([0.90949707, 0.8188697, 0.87795304]),\n",
    "        std=np.array([0.36357649, 0.49984502, 0.40477625]),\n",
    "        N=16,\n",
    "        zoom_level=2,\n",
    "        crop_size=128,\n",
    "        label_smoothing=0.15,\n",
    "        output_type='classification',\n",
    "        *args,\n",
    "            **kwargs):\n",
    "        \"\"\"Prepares pytorch dataset for training\n",
    "        Generates tiles from coarse slide and returns it\n",
    "\n",
    "        Args:\n",
    "            data_df (pd.DataFrame): data.frame with slides id and labels.\n",
    "            augmentations (albumentations.compose): augmentations.\n",
    "            image_dir (str): folder with images.\n",
    "            mask_dir (str): folder with masks.\n",
    "            crop_size(int): crop size around mask. Default: 128\n",
    "        Returns\n",
    "            Dataset\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_df = pd.read_csv(data_df)\n",
    "        self.image_dir = image_dir\n",
    "        self.crop_size = crop_size\n",
    "        self.N = N\n",
    "        self.transforms = self._get_aug(transforms_json)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.zoom_level = zoom_level\n",
    "        self.output_type = output_type\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.targets = self.data_df.isup_grade.unique().astype(str)\n",
    "\n",
    "    def _get_aug(self, arg):\n",
    "        with open(arg) as f:\n",
    "            augs = A.from_dict(json.load(f))\n",
    "        target = {}\n",
    "        for i in range(1, self.N):\n",
    "            target['image' + str(i)] = 'image'\n",
    "        return A.Compose(augs, p=1, additional_targets=target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return(len(self.data_df))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Will load the mask, get random coordinates around/with the mask,\n",
    "        load the image by coordinates\n",
    "        \"\"\"\n",
    "        slide_id = self.data_df.image_id.values[idx]\n",
    "        isup_grade = self.data_df.isup_grade.values[idx]\n",
    "        isup_grade_class = self.data_df.isup_grade.values[idx]\n",
    "        input_file = os.path.join(self.image_dir, f\"{slide_id}_{self.zoom_level}_{self.N}_{self.crop_size}.pkl\")\n",
    "        with open(input_file, \"rb\") as input_file:\n",
    "            tiled_images = pickle.load(input_file)\n",
    "        target_names = ['image' + str(i) if i > 0 else 'image'\n",
    "                        for i in range(len(tiled_images))]\n",
    "        tiled_images = dict(zip(\n",
    "            target_names,\n",
    "            tiled_images))\n",
    "        augmented = self.transforms(**tiled_images)\n",
    "        tiled_images = [augmented[target] for target in target_names]\n",
    "        tiled_images = np.stack(tiled_images)\n",
    "        tiled_images = (1.0 - tiled_images/255.0)\n",
    "        tiled_images = (tiled_images - self.mean)/self.std\n",
    "        assert len(tiled_images) == self.N\n",
    "        tiled_images = tiled_images.transpose(0, 3, 1, 2)\n",
    "        # Fix outputs for each of the tasks\n",
    "        # To do: move as separate function\n",
    "        if self.output_type == 'regression':\n",
    "            isup_grade = np.expand_dims(isup_grade, 0)\n",
    "            isup_grade = torch.from_numpy(isup_grade).float()\n",
    "        elif self.output_type == 'classification':\n",
    "            isup_grade = torch.tensor(isup_grade)\n",
    "        elif self.output_type == 'ordinal':\n",
    "            raise NotImplementedError\n",
    "        elif self.output_type == 'ohe_classification':\n",
    "            '''\n",
    "            We can make it asymetric if we use the assumption that\n",
    "            errors 4-5 are more likely than errors 0-5\n",
    "            '''\n",
    "            ohe_isup_grade = np.zeros(6)\n",
    "            ohe_isup_grade[isup_grade] = 1\n",
    "            isup_grade = ohe_isup_grade\n",
    "            isup_grade = isup_grade * (1 - self.label_smoothing) + \\\n",
    "                self.label_smoothing / 6\n",
    "            isup_grade = torch.from_numpy(isup_grade).float()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        data = {'features': torch.from_numpy(tiled_images).float(),\n",
    "                'targets': isup_grade,\n",
    "                'metric_learning_targets': isup_grade_class}\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet34'\n",
    "embedding_size = 128\n",
    "pretrained = True\n",
    "num_classes = 1\n",
    "\n",
    "# Create the trunk\n",
    "model = TrunkMultiCropModel(\n",
    "    model_name,\n",
    "    num_classes,\n",
    "    embedding_size,\n",
    "    pretrained=pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS = '/data/personal_folders/skolchenko/panda/train_cleaned.csv'\n",
    "train_labes = pd.read_csv(TRAIN_LABELS)\n",
    "data_train, data_val = train_test_split(\n",
    "    train_labes,\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "data_train.to_csv(\n",
    "    '/data/personal_folders/skolchenko/panda/data_train_cleaned.csv',\n",
    "    index=False)\n",
    "data_val.to_csv(\n",
    "    '/data/personal_folders/skolchenko/panda/data_val_cleaned.csv',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PickleMetricLearningAndClassifcationDatasetMultiCrop(\n",
    "    \"/data/personal_folders/skolchenko/panda/data_train_cleaned.csv\",\n",
    "    \"../configs/light_transforms_noNorm.json\",\n",
    "    \"/data/personal_folders/skolchenko/panda/pickled_tiled_images\",\n",
    "    N=16, \n",
    "    zoom_level=1,\n",
    "    crop_size=128, \n",
    "    output_type='regression')\n",
    "\n",
    "val_dataset = PickleMetricLearningAndClassifcationDatasetMultiCrop(\n",
    "    \"/data/personal_folders/skolchenko/panda/data_val_cleaned.csv\",\n",
    "    \"../configs/validation_augs_noNorm.json\",\n",
    "    \"/data/personal_folders/skolchenko/panda/pickled_tiled_images\",\n",
    "    N=16, \n",
    "    zoom_level=1,\n",
    "    crop_size=128, \n",
    "    output_type='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.TripletMarginLoss(margin=0.1)\n",
    "classification_loss = torch.nn.MSELoss()\n",
    "miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "sampler = samplers.MPerClassSampler(train_dataset.targets, m=4, length_before_new_iter=len(train_dataset))\n",
    "batch_size = 24\n",
    "loss_funcs = {\"metric_loss\": loss, \"classifier_loss\": classification_loss}\n",
    "mining_funcs = {\"tuple_miner\": miner}\n",
    "loss_weights = {\"metric_loss\": 10, \"classifier_loss\": 1}                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLearningClassifierRunner(dl.Runner):\n",
    "    def __init__(\n",
    "        self, \n",
    "        mining_funcs,\n",
    "        loss_funcs,\n",
    "        loss_weights,\n",
    "        model = None, \n",
    "        device = None,  \n",
    "      ):\n",
    "        super().__init__(model, device)\n",
    "        self.mining_funcs = mining_funcs\n",
    "        self.loss_funcs = loss_funcs\n",
    "        self.loss_weights = loss_weights\n",
    "        \n",
    "    def get_final_embeddings(self, base_output):\n",
    "        return self.model[\"embedder\"](base_output.cuda())\n",
    "\n",
    "    def get_model_output(self, data):\n",
    "        return self.model(data.cuda())\n",
    "\n",
    "    def mine_embeddings(self, embeddings, labels):\n",
    "        return self.mining_funcs[\"tuple_miner\"](embeddings.cuda(), labels.cuda())\n",
    "    \n",
    "    def get_classifier_loss(self, logits, labels):\n",
    "        return self.loss_funcs[\"classifier_loss\"](logits.cuda(), labels.cuda())\n",
    "\n",
    "    def get_logits(self, embeddings):\n",
    "        return self.model[\"classifier\"](embeddings)\n",
    "  \n",
    "    def get_metric_loss(self, embeddings, labels, indices_tuple):\n",
    "        return self.loss_funcs[\"metric_loss\"](embeddings, labels, indices_tuple)\n",
    "    \n",
    "    def _handle_batch(self, batch):\n",
    "        batch_metrics = {}\n",
    "        data  = batch['features']\n",
    "        labels_classifier = batch['targets']\n",
    "        labels = batch['metric_learning_targets']\n",
    "        cls_output, embedding_output = self.get_model_output(data) # trunk output\n",
    "        indices_tuple = self.mine_embeddings(embedding_output, labels) # mining for metric learning\n",
    "        metric_loss = self.loss_weights['metric_loss']*self.get_metric_loss(embedding_output, labels, indices_tuple)\n",
    "        classifier_loss = self.loss_weights['classifier_loss']*self.get_classifier_loss(cls_output, labels_classifier)\n",
    "        loss = metric_loss + classifier_loss\n",
    "        batch_metrics[\"metric_loss\"] = metric_loss\n",
    "        batch_metrics[\"classifier_loss\"] = classifier_loss\n",
    "        batch_metrics[\"loss\"] = loss\n",
    "        self.state.batch_metrics.update(**batch_metrics)  \n",
    "        self.state.output = {\"logits\": cls_output}\n",
    "        if self.state.is_train_loader:\n",
    "            loss.backward()\n",
    "            self.state.optimizer.step()\n",
    "            self.state.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "  \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=64),\n",
    "  \"valid\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=64)\n",
    "}\n",
    "\n",
    "runner = MetricLearningClassifierRunner(\n",
    "    mining_funcs=mining_funcs,\n",
    "    loss_weights=loss_weights,\n",
    "    loss_funcs=loss_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"./exp_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/25 * Epoch (train): 100% 311/312 [02:29<00:00,  2.17it/s, batch_qwk=0.395, classifier_loss=2.078, loss=3.459, metric_loss=1.380]     "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-776f3fd7958b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQWKCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqwk_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'simple'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/dl/runner/core.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, distributed, check, timeit, load_best_on_end, initial_seed)\u001b[0m\n\u001b[1;32m    155\u001b[0m         )\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     def infer(\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     ):\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    518\u001b[0m             ):\n\u001b[1;32m    519\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \"\"\"\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     def _batch2device(\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/callbacks/exception.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_exception_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    481\u001b[0m             )\n\u001b[1;32m    482\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, stage, epoch)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-afcb2a7f07e5>\u001b[0m in \u001b[0;36m_handle_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric_learning_targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcls_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# trunk output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mindices_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmine_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mining for metric learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmetric_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metric_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mclassifier_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classifier_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-afcb2a7f07e5>\u001b[0m in \u001b[0;36mmine_embeddings\u001b[0;34m(self, embeddings, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmine_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmining_funcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuple_miner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_classifier_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/pytorch_metric_learning/miners/base_miner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, labels, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mref_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ref_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mmining_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   3043\u001b[0m     \"\"\"\n\u001b[1;32m   3044\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3045\u001b[0;31m         \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;34mr\"\"\"See :func:`torch.norm`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "optimizer = RAdam(model.parameters(), lr=1e-4)\n",
    "optimizer_la = Lookahead(optimizer)\n",
    "runner.train(\n",
    "    model=model, \n",
    "    optimizer=optimizer_la,\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=5, factor=0.1),\n",
    "    loaders=loaders,\n",
    "    main_metric=\"classifier_loss\",\n",
    "    num_epochs=num_epochs,\n",
    "    callbacks=[QWKCallback(qwk_name='simple')],\n",
    "    verbose=True,\n",
    "    logdir=logdir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "optimizer = RAdam(model.parameters(), lr=1e-5)\n",
    "optimizer_la = Lookahead(optimizer)\n",
    "runner.train(\n",
    "    model=model, \n",
    "    optimizer=optimizer_la,\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=5, factor=0.1),\n",
    "    loaders=loaders,\n",
    "    main_metric=\"classifier_loss\",\n",
    "    num_epochs=num_epochs,\n",
    "    callbacks=[QWKCallback(qwk_name='simple')],\n",
    "    verbose=True,\n",
    "    logdir=logdir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "optimizer = RAdam(model.parameters(), lr=1e-6)\n",
    "optimizer_la = Lookahead(optimizer)\n",
    "runner.train(\n",
    "    model=model, \n",
    "    optimizer=optimizer_la,\n",
    "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=5, factor=0.1),\n",
    "    loaders=loaders,\n",
    "    main_metric=\"classifier_loss\",\n",
    "    num_epochs=num_epochs,\n",
    "    callbacks=[QWKCallback(qwk_name='simple')],\n",
    "    verbose=True,\n",
    "    logdir=logdir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PickleMetricLearningAndClassifcationDatasetMultiCrop(\n",
    "    \"/data/personal_folders/skolchenko/panda/data_train_cleaned.csv\",\n",
    "    \"../configs/validation_augs_noNorm.json\",\n",
    "    \"/data/personal_folders/skolchenko/panda/pickled_tiled_images\",\n",
    "    N=16, \n",
    "    zoom_level=1,\n",
    "    crop_size=128, \n",
    "    output_type='regression')\n",
    "\n",
    "val_dataset = PickleMetricLearningAndClassifcationDatasetMultiCrop(\n",
    "    \"/data/personal_folders/skolchenko/panda/data_val_cleaned.csv\",\n",
    "    \"../configs/validation_augs_noNorm.json\",\n",
    "    \"/data/personal_folders/skolchenko/panda/pickled_tiled_images\",\n",
    "    N=16, \n",
    "    zoom_level=1,\n",
    "    crop_size=128, \n",
    "    output_type='regression')\n",
    "loaders = {\n",
    "  \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=48),\n",
    "  \"valid\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=48)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cls = []\n",
    "embeddings = []\n",
    "targets = []\n",
    "for batch in tqdm(loaders['train'], total=len(loaders['train'])):\n",
    "    with torch.no_grad():\n",
    "        pred_cls, pred_emb = model(batch['features'].cuda())\n",
    "        pred_cls = pred_cls.cpu().numpy()\n",
    "        pred_emb = pred_emb.cpu().numpy()\n",
    "        embeddings.extend(pred_emb)\n",
    "        predicted_cls.extend(pred_cls)\n",
    "        targets.extend(batch['targets'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([x[0] for x in predicted_cls])\n",
    "preds[preds<0] = 0\n",
    "preds[preds>5] = 5\n",
    "preds = np.round(preds).astype(int)\n",
    "cohen_kappa_score(targets, preds, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cls_valid = []\n",
    "embeddings_valid = []\n",
    "targets_valid = []\n",
    "for batch in tqdm(loaders['valid'], total=len(loaders['valid'])):\n",
    "    with torch.no_grad():\n",
    "        pred_cls, pred_emb = model(batch['features'].cuda())\n",
    "        pred_cls = pred_cls.cpu().numpy()\n",
    "        pred_emb = pred_emb.cpu().numpy()\n",
    "        embeddings_valid.extend(pred_emb)\n",
    "        predicted_cls_valid.extend(pred_cls)\n",
    "        targets_valid.extend(batch['targets'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = np.array([x[0] for x in predicted_cls_valid])\n",
    "preds_valid[preds_valid<0] = 0\n",
    "preds_valid[preds_valid>5] = 5\n",
    "preds_valid = np.round(preds_valid).astype(int)\n",
    "cohen_kappa_score(targets_valid, preds_valid, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_valid = np.stack(embeddings_valid)\n",
    "predicted_cls_valid = np.stack(predicted_cls_valid)\n",
    "targets_valid = np.stack(targets_valid)\n",
    "embeddings = np.stack(embeddings)\n",
    "predicted_cls = np.stack(predicted_cls)\n",
    "targets = np.stack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = umap.UMAP(n_neighbors=15,\n",
    "                        min_dist=0.01, \n",
    "                        spread=2)\n",
    "transformer.fit(embeddings)\n",
    "embeddings_umap = transformer.transform(embeddings)\n",
    "embeddings_valid_umap = transformer.transform(embeddings_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1], c=[x[0] for x in targets], cmap='YlOrRd', s=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embeddings_valid_umap[:, 0], embeddings_valid_umap[:, 1], c=[x[0] for x in targets_valid],\n",
    "            cmap='YlOrRd', marker='*', s=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_knn(hps, X, y, ncv=10, SEED=42):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/fanvacoolt/tutorial-on-hyperopt\n",
    "    \"\"\"\n",
    "    model = KNeighborsRegressor(**hps)\n",
    "    cv_res = cross_val_score(model, X, y, cv=StratifiedKFold(ncv, random_state=SEED, shuffle=True),\n",
    "                             scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    return {\n",
    "        'loss': -cv_res.mean(),\n",
    "        'cv_std': cv_res.std(),\n",
    "        'status': STATUS_OK\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "hp_space_knn = {\n",
    "            'weights': hp.choice('weights', ['uniform', 'distance']),\n",
    "            'n_neighbors': hp.choice('n_neighbors', range(1, 50)),\n",
    "            }\n",
    "\n",
    "trials_knn = Trials() \n",
    "best_knn = fmin(partial(opt_knn, X=embeddings_umap, y=targets), \n",
    "               hp_space_knn, \n",
    "               algo=tpe.suggest,\n",
    "               max_evals=25, # Should be enough \n",
    "               trials=trials_knn, \n",
    "               rstate=np.random.RandomState(SEED))\n",
    "print(best_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsRegressor(n_neighbors=18, weights='distance')\n",
    "clf.fit(embeddings_umap, targets.astype(int))\n",
    "predictions_knn = clf.predict(embeddings_valid_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = np.array([x[0] for x in predicted_cls_valid])\n",
    "preds_valid[preds_valid<0] = 0\n",
    "preds_valid[preds_valid>5] = 5\n",
    "preds_valid = np.round(preds_valid).astype(int)\n",
    "cohen_kappa_score([int(x[0]) for x in targets_valid], preds_valid, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid_knn = np.array([x[0] for x in predictions_knn])\n",
    "preds_valid_knn[preds_valid_knn<0] = 0\n",
    "preds_valid_knn[preds_valid_knn>5] = 5\n",
    "preds_valid_knn = np.round(preds_valid_knn).astype(int)\n",
    "cohen_kappa_score([int(x[0]) for x in targets_valid], preds_valid_knn, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_preds = np.array([x[0] for x in predicted_cls_valid]) + np.array([x[0] for x in predictions_knn])\n",
    "mixed_preds = mixed_preds / 2\n",
    "mixed_preds = np.round(mixed_preds)\n",
    "mixed_preds[mixed_preds<0] = 0\n",
    "mixed_preds[mixed_preds>5] = 5\n",
    "mixed_preds = mixed_preds.astype(int)\n",
    "cohen_kappa_score([int(x[0]) for x in targets_valid], mixed_preds, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lookahead (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    counter: 0\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lookahead(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAdam (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    counter: 0\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python37564bitdeeplearningconda2f5dcc693383402099797ed40bd3951d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
