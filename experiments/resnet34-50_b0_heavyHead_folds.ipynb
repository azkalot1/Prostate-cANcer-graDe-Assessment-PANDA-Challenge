{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skolchenko/.local/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/graphql/type/directives.py:55: DeprecationWarning:\n",
      "\n",
      "Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torchvision/_C.so'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from panda_challenge import ClassifcationDatasetMultiCropOneImage\n",
    "from panda_challenge.train_utils import QWKCallback, get_optimizer, get_scheduler\n",
    "from panda_challenge import ClassifcationModel\n",
    "from panda_challenge.models import AdaptiveConcatPool2d\n",
    "from panda_challenge.utils import freeze, unfreeze\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR\n",
    "import torch\n",
    "from catalyst.contrib.nn.schedulers.onecycle import OneCycleLRWithWarmup\n",
    "from catalyst.contrib.nn.optimizers import RAdam, Lookahead\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.dl.callbacks import CriterionCallback\n",
    "from catalyst.core.callbacks import EarlyStoppingCallback\n",
    "from catalyst.core.callbacks import MetricAggregationCallback\n",
    "from catalyst.core.callbacks import CheckpointCallback\n",
    "\n",
    "from pytorch_toolbelt.losses import BinaryFocalLoss\n",
    "\n",
    "import os \n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "N_TILES = 49\n",
    "IMAGE_SIZE = 256\n",
    "LEVEL = 1\n",
    "BATCH_SIZE = 12\n",
    "NUM_WORKERS = 64\n",
    "N_EPOCHS = 100\n",
    "N_FROZEN_ENCODER = 1\n",
    "WARMUP_EPOCHS = 5\n",
    "INIT_LR = 3e-4\n",
    "WARMUP_FACTOR = 10\n",
    "NUM_CLASSES = 5\n",
    "IMAGE_FOLDER = '/data/personal_folders/skolchenko/panda/train_images/'\n",
    "N_TILES_ROW = int(np.sqrt(N_TILES))\n",
    "LOG_DIR = '/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles49_heavyHead_fold{}'\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train_individual = A.Compose([\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.ElasticTransform(p=1.0),\n",
    "        A.GridDistortion(p=1.0),\n",
    "        A.OpticalDistortion(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.GaussNoise(p=1.0),\n",
    "        A.GaussianBlur(p=1.0),\n",
    "        A.ISONoise(p=1.0),\n",
    "        A.CoarseDropout(p=1.0, max_holes=16, max_height=16, max_width=16),\n",
    "        A.NoOp()\n",
    "    ], p=1.0)\n",
    "])\n",
    "transforms_train_global = A.Compose([\n",
    "    A.Normalize(),\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.RandomGridShuffle(grid=(N_TILES_ROW, N_TILES_ROW))\n",
    "])\n",
    "transforms_train_global_tta = A.Compose([\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.RandomGridShuffle(grid=(N_TILES_ROW, N_TILES_ROW), p=1.0),\n",
    "    A.Normalize()\n",
    "])\n",
    "transforms_valid_global = A.Compose([\n",
    "    A.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into validation and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/personal_folders/skolchenko/panda/train_cleaned.csv')\n",
    "data_train, data_holdout = train_test_split(data, test_size=0.15, random_state=42, shuffle=True, stratify=data.isup_grade)\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "data_holdout = data_holdout.reset_index(drop=True)\n",
    "data_train.loc[:, 'fold_idx'] = -1\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold_idx, (train_index, test_index) in enumerate(skf.split(data_train, data_train.isup_grade.values, groups=data_train.isup_grade.values)):\n",
    "    data_train.loc[test_index, 'fold_idx'] = fold_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>fold_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632a836af7b82fc1351e5e6955a33c9c</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c434b351328d1202d90d7468be10c46b</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>5+4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da0c4c33709fb5d3372c7e0685b6a767</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b993648443f3e9ff352b64202528592b</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3ca86b49aa2b914b30f2dd25c0431b9c</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>5+4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  632a836af7b82fc1351e5e6955a33c9c    karolinska           1           3+3   \n",
       "1  c434b351328d1202d90d7468be10c46b       radboud           5           5+4   \n",
       "2  da0c4c33709fb5d3372c7e0685b6a767    karolinska           1           3+3   \n",
       "3  b993648443f3e9ff352b64202528592b    karolinska           1           3+3   \n",
       "4  3ca86b49aa2b914b30f2dd25c0431b9c       radboud           5           5+4   \n",
       "\n",
       "   fold_idx  \n",
       "0         3  \n",
       "1         1  \n",
       "2         3  \n",
       "3         0  \n",
       "4         3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'ecaresnet18',\n",
       " 'ecaresnet50',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26tn_32x4d',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'fbnetc_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1e',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1e',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1e',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gluon_xception71',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_a1',\n",
       " 'mnasnet_b1',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'nasnetalarge',\n",
       " 'pnasnet5large',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resnet18',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnet50d',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'seresnet18',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnext26_32x4d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26tn_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(fold_idx):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    #criterion = nn.MSELoss()\n",
    "    model = ClassifcationModel(model_name='resnet34', num_classes=NUM_CLASSES, pretrained=True)\n",
    "    model.head = nn.Sequential(\n",
    "                AdaptiveConcatPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(2*model.nc, model.nc//2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.15),                \n",
    "                nn.Linear(model.nc//2, NUM_CLASSES))\n",
    "    model.cuda()    \n",
    "    \n",
    "    fold_data_train = data_train.loc[data_train['fold_idx']!=fold_idx]\n",
    "    fold_data_val = data_train.loc[data_train['fold_idx']==fold_idx]    \n",
    "    \n",
    "    train_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        fold_data_train, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_individual=transforms_train_individual,\n",
    "        transform_global=transforms_train_global,\n",
    "        normalize=False,\n",
    "        load_pickled_tiles=False,\n",
    "        #pickled_tiles_folder='/data/personal_folders/skolchenko/panda/pickled_tiled_images_{}_{}_{}'.format(LEVEL,\n",
    "        #                                                                                                    N_TILES, \n",
    "        #                                                                                                    IMAGE_SIZE),\n",
    "        output_type='ordinal'\n",
    "        )\n",
    "    val_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        fold_data_val, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_global=transforms_valid_global,\n",
    "        normalize=False,\n",
    "        load_pickled_tiles=False,\n",
    "        #pickled_tiles_folder='/data/personal_folders/skolchenko/panda/pickled_tiled_images_{}_{}_{}'.format(LEVEL,\n",
    "        #                                                                                                    N_TILES, \n",
    "        #                                                                                                    IMAGE_SIZE),\n",
    "        output_type='ordinal'\n",
    "        )\n",
    "    holdout_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        data_holdout, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_global=transforms_valid_global,\n",
    "        normalize=False,\n",
    "        #pickled_tiles_folder='/data/personal_folders/skolchenko/panda/pickled_tiled_images_{}_{}_{}'.format(LEVEL,\n",
    "        #                                                                                                    N_TILES, \n",
    "        #                                                                                                    IMAGE_SIZE),\n",
    "        #load_pickled_tiles=True,       \n",
    "        output_type='ordinal'\n",
    "        )    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)  \n",
    "    holdout_loader = DataLoader(holdout_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)  \n",
    "    \n",
    "    loaders = collections.OrderedDict()\n",
    "    loaders[\"train\"] = train_loader\n",
    "    loaders[\"valid\"] = val_loader\n",
    "    loaders[\"holdout\"] = holdout_loader\n",
    "    losses = dict({\n",
    "        'loss_isup': criterion,\n",
    "    })\n",
    "    runner = SupervisedRunner(\n",
    "        input_key='features',\n",
    "        input_target_key=\"targets_isup\",\n",
    "        output_key=\"logits_isup\"\n",
    "        )    \n",
    "    \n",
    "    callbacks = [\n",
    "        CriterionCallback(\n",
    "            input_key=\"targets_isup\",\n",
    "            output_key=\"logits_isup\",\n",
    "            prefix=\"loss_isup\",\n",
    "            criterion_key='loss_isup',\n",
    "            multiplier=1.0\n",
    "        ),\n",
    "        QWKCallback(input_key=\"targets_isup\", \n",
    "                    output_key='logits_isup',\n",
    "                    qwk_name='ordinal'\n",
    "                    #qwk_name='simple',\n",
    "                   ),\n",
    "        MetricAggregationCallback(\n",
    "            prefix=\"loss\",\n",
    "            mode=\"weighted_sum\",\n",
    "            metrics={\n",
    "                \"loss_isup\": 1.0\n",
    "            }\n",
    "        ),\n",
    "        EarlyStoppingCallback(patience = PATIENCE, min_delta=1e-4),\n",
    "        CheckpointCallback(save_n_best = 5)    \n",
    "    ]    \n",
    "    \n",
    "    freeze(model)\n",
    "    optimizer = RAdam(model.parameters(), lr=INIT_LR)\n",
    "    optimizer = Lookahead(optimizer)\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=losses,\n",
    "        optimizer=optimizer,\n",
    "        callbacks=callbacks,\n",
    "        loaders=loaders,\n",
    "        logdir=LOG_DIR.format(fold_idx),\n",
    "        main_metric='loss',\n",
    "        num_epochs=N_FROZEN_ENCODER,\n",
    "        verbose=True,\n",
    "        minimize_metric=True,\n",
    "        fp16=True\n",
    "    )    \n",
    "    model.load_state_dict(torch.load(LOG_DIR.format(fold_idx)+'/checkpoints/best.pth')['model_state_dict'])\n",
    "    \n",
    "    \n",
    "    unfreeze(model)\n",
    "    optimizer = RAdam(model.parameters(), lr=INIT_LR/WARMUP_FACTOR)\n",
    "    optimizer = Lookahead(optimizer)\n",
    "    scheduler_cosine = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        N_EPOCHS-WARMUP_EPOCHS)\n",
    "    scheduler = GradualWarmupScheduler(\n",
    "        optimizer,\n",
    "        multiplier=WARMUP_FACTOR, \n",
    "        total_epoch=WARMUP_EPOCHS,\n",
    "        after_scheduler=scheduler_cosine)    \n",
    "    \n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=losses,\n",
    "        scheduler=scheduler,\n",
    "        optimizer=optimizer,\n",
    "        callbacks=callbacks,\n",
    "        loaders=loaders,\n",
    "        logdir=LOG_DIR.format(fold_idx),\n",
    "        main_metric='loss',\n",
    "        num_epochs=N_EPOCHS,\n",
    "        verbose=True,\n",
    "        minimize_metric=True,\n",
    "        fp16=True\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "1/1 * Epoch (train):   0% 0/564 [00:00<?, ?it/s]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "1/1 * Epoch (train):   0% 1/564 [01:14<11:37:09, 74.30s/it, batch_qwk=-1.613e-01, loss=2.783, loss_isup=2.783]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "1/1 * Epoch (train):   0% 2/564 [01:29<8:51:15, 56.72s/it, batch_qwk=-9.091e-02, loss=2.437, loss_isup=2.437] Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "1/1 * Epoch (train): 100% 564/564 [13:21<00:00,  1.42s/it, batch_qwk=0.242, loss=0.591, loss_isup=0.591]      \n",
      "1/1 * Epoch (valid): 100% 141/141 [03:10<00:00,  1.35s/it, batch_qwk=0.200, loss=0.619, loss_isup=0.619]     \n",
      "1/1 * Epoch (holdout): 100% 125/125 [02:23<00:00,  1.15s/it, batch_qwk=0.364, loss=0.658, loss_isup=0.658]     \n",
      "[2020-07-12 10:19:12,874] \n",
      "1/1 * Epoch 1 (_base): lr=0.0003 | momentum=0.9000\n",
      "1/1 * Epoch 1 (train): batch_qwk=0.0460 | loss=1.0350 | loss_isup=1.0350 | qwk=0.0482\n",
      "1/1 * Epoch 1 (valid): batch_qwk=0.1983 | loss=0.6234 | loss_isup=0.6234 | qwk=0.2246\n",
      "1/1 * Epoch 1 (holdout): batch_qwk=0.1788 | loss=0.6231 | loss_isup=0.6231 | qwk=0.1868\n",
      "Top best models:\n",
      "/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles49_heavyHead_fold0/checkpoints/train.1.pth\t0.6234\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "1/100 * Epoch (train):   7% 41/564 [02:25<10:45,  1.23s/it, batch_qwk=0.057, loss=0.520, loss_isup=0.520]      "
     ]
    }
   ],
   "source": [
    "train_fold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(state_dicts: List[dict]):\n",
    "    # source https://gist.github.com/qubvel/70c3d5e4cddcde731408f478e12ef87b\n",
    "    everage_dict = OrderedDict()\n",
    "    for k in state_dicts[0].keys():\n",
    "        everage_dict[k] = sum([state_dict[k] for state_dict in state_dicts]) / len(state_dicts)\n",
    "    return everage_dict\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    # source https://gist.github.com/qubvel/70c3d5e4cddcde731408f478e12ef87b\n",
    "    model.eval()\n",
    "    predicted_class = []\n",
    "    gt_class = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, total=len(val_loader)):\n",
    "            predictions = model(batch['features'].cuda())\n",
    "            predictions = nn.Sigmoid()(predictions)\n",
    "            predicted_class.extend(predictions.sum(dim=1).cpu().round().numpy())\n",
    "            gt_class.extend(batch['targets_isup'].sum(dim=1).cpu().numpy())\n",
    "    gt_class = np.array(gt_class).astype(int)\n",
    "    predicted_class = np.array(predicted_class).astype(int)\n",
    "    return(cohen_kappa_score(predicted_class, gt_class, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_epochs = [\n",
    "    [38, 30, 42, 43, 29],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fold_idx in range(5):\n",
    "for fold_idx in range(1):\n",
    "    print(f'====== Fold {fold_idx} =====')\n",
    "    model = ClassifcationModel(model_name='resnet50', num_classes=NUM_CLASSES, pretrained=True)\n",
    "    model.head = nn.Sequential(\n",
    "                AdaptiveConcatPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(2*model.nc, model.nc//2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.15),                \n",
    "                nn.Linear(model.nc//2, NUM_CLASSES))\n",
    "    model.cuda()    \n",
    "    \n",
    "    fold_data_train = data_train.loc[data_train['fold_idx']!=fold_idx]\n",
    "    fold_data_val = data_train.loc[data_train['fold_idx']==fold_idx]    \n",
    "    \n",
    "    val_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        fold_data_val, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_global=transforms_valid_global,\n",
    "        normalize=False,\n",
    "        #load_pickled_tiles=True,\n",
    "        #pickled_tiles_folder='/data/personal_folders/skolchenko/panda/pickled_tiled_images_{}_{}_{}'.format(LEVEL,\n",
    "        #                                                                                                    N_TILES, \n",
    "        #                                                                                                    IMAGE_SIZE)\n",
    "        )    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)  \n",
    "    \n",
    "    weights_path = [os.path.join(LOG_DIR.format(fold_idx), f'checkpoints/train.{epoch}.pth') for epoch in fold_epochs[fold_idx]]\n",
    "    all_weights = [torch.load(path)['model_state_dict'] for path in weights_path]\n",
    "\n",
    "    best_score = 0\n",
    "    best_weights = []\n",
    "\n",
    "    for w in all_weights:\n",
    "        current_weights = best_weights + [w]\n",
    "        average_dict = average_weights(current_weights)\n",
    "        model.load_state_dict(average_dict)\n",
    "        score = evaluate_model(model, val_loader)\n",
    "        print(f'Score: {score}')\n",
    "        if score > best_score:\n",
    "            print(f'New best score {score}')\n",
    "            best_score = score\n",
    "            best_weights.append(w)    \n",
    "            \n",
    "    best_dict = average_weights(best_weights)\n",
    "    model.load_state_dict(best_dict)\n",
    "    torch.save(model.state_dict(), os.path.join(LOG_DIR.format(fold_idx), f'checkpoints/averaged_best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make TTA + 5 fold predictions on holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_same(weight_paths):\n",
    "    models = []\n",
    "    for fold_idx in range(5):\n",
    "        model = ClassifcationModel(model_name='efficientnet_b0', num_classes=NUM_CLASSES, pretrained=True)\n",
    "        model.head = nn.Sequential(\n",
    "                    AdaptiveConcatPool2d((1, 1)),\n",
    "                    nn.Flatten(),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(2*model.nc, model.nc//2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.15),                \n",
    "                    nn.Linear(model.nc//2, NUM_CLASSES))\n",
    "        model.cuda()    \n",
    "        model.load_state_dict(torch.load(weight_paths[fold_idx]))\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_paths  = [os.path.join(LOG_DIR.format(fold_idx), f'checkpoints/averaged_best.pth') for fold_idx in range(5)]\n",
    "models = load_models_same(weight_paths)\n",
    "holdout_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "    data_holdout, \n",
    "    IMAGE_SIZE,\n",
    "    IMAGE_FOLDER,\n",
    "    LEVEL,\n",
    "    N_TILES,\n",
    "    transform_global=transforms_valid_global,\n",
    "    normalize=False,\n",
    "    #load_pickled_tiles=True,\n",
    "    #pickled_tiles_folder='/data/personal_folders/skolchenko/panda/pickled_tiled_images_{}_{}_{}'.format(LEVEL,\n",
    "    #                                                                                                    N_TILES, \n",
    "    #                                                                                                    IMAGE_SIZE)\n",
    "    )    \n",
    "holdout_loader = DataLoader(holdout_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_additional_images = 7\n",
    "n_models = 5\n",
    "average_technique = 'fold_first'\n",
    "predicted_labels = []\n",
    "gt_labels = []\n",
    "thr_class = 0.75\n",
    "for data in tqdm(holdout_loader, total=len(holdout_loader)):\n",
    "    image_original = data['features'][0].cpu().numpy().transpose((1,2,0))\n",
    "    augmented_images = [image_original] +\\\n",
    "        [transforms_train_global_tta(image=image_original)['image'] for x in range(n_additional_images)]\n",
    "    augmented_images = torch.from_numpy(np.stack(augmented_images).transpose((0, 3, 1, 2)))\n",
    "    gt_label = data['targets_isup'].sum().cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        image_pred = [nn.Sigmoid()(model(augmented_images.cuda())) for model in models]\n",
    "        image_pred = torch.stack(image_pred)\n",
    "    if average_technique == 'flatten_all':\n",
    "        predicted_label = ((image_pred.view(-1, 5) >= thr_class).sum(axis=1).float().sum() / ((n_additional_images+1)*n_models)).round().cpu().numpy()\n",
    "        if predicted_label > 5:\n",
    "            predicted_label = 5  # dirty little hack\n",
    "    elif average_technique == 'fold_first':\n",
    "        predicted_label = (image_pred.mean(dim=0).mean(dim=0) >= thr_class).sum().cpu().numpy()\n",
    "    elif  average_technique == 'images_first':   \n",
    "        predicted_label = (image_pred.mean(dim=1).mean(dim=0) >= thr_class).sum().cpu().numpy()\n",
    "    predicted_labels.append(predicted_label)\n",
    "    gt_labels.append(gt_label)\n",
    "    #print(gt_label, predicted_label)\n",
    "predicted_labels = np.array(predicted_labels).astype(int)\n",
    "gt_labels = np.array(gt_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(predicted_labels, gt_labels, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python37564bitdeeplearningconda2f5dcc693383402099797ed40bd3951d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
