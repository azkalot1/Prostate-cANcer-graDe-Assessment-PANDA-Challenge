{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skolchenko/.local/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/graphql/type/directives.py:55: DeprecationWarning:\n",
      "\n",
      "Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "\n",
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torchvision/_C.so'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from panda_challenge import ClassifcationDatasetMultiCropOneImage\n",
    "from panda_challenge.train_utils import QWKCallback, get_optimizer, get_scheduler\n",
    "from panda_challenge import ClassifcationModel\n",
    "from panda_challenge.models import AdaptiveConcatPool2d\n",
    "from panda_challenge.utils import freeze, unfreeze\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR\n",
    "import torch\n",
    "from catalyst.contrib.nn.schedulers.onecycle import OneCycleLRWithWarmup\n",
    "from catalyst.contrib.nn.optimizers import RAdam, Lookahead\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.dl.callbacks import CriterionCallback\n",
    "from catalyst.core.callbacks import EarlyStoppingCallback\n",
    "from catalyst.core.callbacks import MetricAggregationCallback\n",
    "from catalyst.core.callbacks import CheckpointCallback\n",
    "\n",
    "from pytorch_toolbelt.losses import BinaryFocalLoss\n",
    "\n",
    "import os \n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "N_TILES = 36\n",
    "IMAGE_SIZE = 256\n",
    "LEVEL = 1\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 64\n",
    "N_EPOCHS = 100\n",
    "N_FROZEN_ENCODER = 5\n",
    "WARMUP_EPOCHS = 5\n",
    "INIT_LR = 3e-4\n",
    "WARMUP_FACTOR = 1\n",
    "NUM_CLASSES = 5\n",
    "IMAGE_FOLDER = '/data/personal_folders/skolchenko/panda/train_images/'\n",
    "N_TILES_ROW = int(np.sqrt(N_TILES))\n",
    "MODEL_NAME = 'resnet34'\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train_individual = A.Compose([\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.ElasticTransform(p=1.0),\n",
    "        A.GridDistortion(p=1.0),\n",
    "        A.OpticalDistortion(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.GaussNoise(p=1.0),\n",
    "        A.GaussianBlur(p=1.0),\n",
    "        A.ISONoise(p=1.0),\n",
    "        A.CoarseDropout(p=1.0, max_holes=16, max_height=16, max_width=16),\n",
    "        A.NoOp()\n",
    "    ], p=1.0)\n",
    "])\n",
    "transforms_train_global = A.Compose([\n",
    "    A.Normalize(),\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.RandomGridShuffle(grid=(N_TILES_ROW, N_TILES_ROW))\n",
    "])\n",
    "transforms_train_global_tta = A.Compose([\n",
    "    A.OneOf(\n",
    "    [\n",
    "        A.Transpose(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.NoOp()\n",
    "    ], p=1.0),\n",
    "    A.RandomGridShuffle(grid=(N_TILES_ROW, N_TILES_ROW), p=1.0),\n",
    "    A.Normalize()\n",
    "])\n",
    "transforms_valid_global = A.Compose([\n",
    "    A.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "      <th>class_3</th>\n",
       "      <th>class_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b993648443f3e9ff352b64202528592b</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.538650</td>\n",
       "      <td>0.082998</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.001731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39f81a4d7b5b86706391dcc09a4c2e94</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978157</td>\n",
       "      <td>0.500730</td>\n",
       "      <td>0.211926</td>\n",
       "      <td>0.078533</td>\n",
       "      <td>0.012538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a5e22243152d5cc871983364ae7b6e95</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340560</td>\n",
       "      <td>0.061330</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1f151640dce9fc4e33569700be7d52d</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070296</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.020019</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.003844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c7c18a00f4c61c696c30c721bf7621d2</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980977</td>\n",
       "      <td>0.335641</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  b993648443f3e9ff352b64202528592b    karolinska           1           3+3   \n",
       "1  39f81a4d7b5b86706391dcc09a4c2e94    karolinska           2           3+4   \n",
       "2  a5e22243152d5cc871983364ae7b6e95    karolinska           0           0+0   \n",
       "3  c1f151640dce9fc4e33569700be7d52d       radboud           0      negative   \n",
       "4  c7c18a00f4c61c696c30c721bf7621d2    karolinska           2           3+4   \n",
       "\n",
       "   fold_idx   class_0   class_1   class_2   class_3   class_4  \n",
       "0         0  0.999334  0.538650  0.082998  0.022668  0.001731  \n",
       "1         0  0.978157  0.500730  0.211926  0.078533  0.012538  \n",
       "2         0  0.340560  0.061330  0.011089  0.003904  0.000478  \n",
       "3         0  0.070296  0.029056  0.020019  0.010508  0.003844  \n",
       "4         0  0.980977  0.335641  0.049245  0.016449  0.001381  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_holdout = pd.read_csv('./pseudolabeled_holdout.csv')\n",
    "data_train = pd.read_csv('./pseudolabeled_data.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(fold_idx):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    #criterion = nn.MSELoss()\n",
    "    LOG_DIR = f'/data/personal_folders/skolchenko/panda/logs/{MODEL_NAME}_size{IMAGE_SIZE}_tiles{N_TILES}_level{LEVEL}_heavyHead_fold{fold_idx}_pseudolabeled'\n",
    "    print(f'Saving to {LOG_DIR}')\n",
    "    model = ClassifcationModel(model_name=MODEL_NAME, num_classes=NUM_CLASSES, pretrained=True)\n",
    "    model.head = nn.Sequential(\n",
    "                AdaptiveConcatPool2d((1, 1)),\n",
    "                nn.Flatten(),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(2*model.nc, model.nc//2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.15),                \n",
    "                nn.Linear(model.nc//2, NUM_CLASSES))\n",
    "    model.cuda()    \n",
    "    \n",
    "    fold_data_train = data_train.loc[data_train['fold_idx']!=fold_idx]\n",
    "    fold_data_val = data_train.loc[data_train['fold_idx']==fold_idx]    \n",
    "    \n",
    "    train_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        fold_data_train, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_individual=transforms_train_individual,\n",
    "        transform_global=transforms_train_global,\n",
    "        normalize=False,\n",
    "        load_pickled_tiles=True,\n",
    "        pickled_tiles_folder=f'/data/personal_folders/skolchenko/panda/pickled_tiled_images_{LEVEL}_{N_TILES}_{IMAGE_SIZE}',\n",
    "        output_type='ordinal',\n",
    "        pseudo_labels_columns=[f'class_{x}' for x in range(5)]\n",
    "        )\n",
    "    val_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        fold_data_val, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_global=transforms_valid_global,\n",
    "        normalize=False,\n",
    "        load_pickled_tiles=True,\n",
    "        pickled_tiles_folder=f'/data/personal_folders/skolchenko/panda/pickled_tiled_images_{LEVEL}_{N_TILES}_{IMAGE_SIZE}',\n",
    "        output_type='ordinal',\n",
    "        pseudo_labels_columns=[f'class_{x}' for x in range(5)]\n",
    "        )\n",
    "    holdout_dataset = ClassifcationDatasetMultiCropOneImage(\n",
    "        data_holdout, \n",
    "        IMAGE_SIZE,\n",
    "        IMAGE_FOLDER,\n",
    "        LEVEL,\n",
    "        N_TILES,\n",
    "        transform_global=transforms_valid_global,\n",
    "        normalize=False,\n",
    "        pickled_tiles_folder=f'/data/personal_folders/skolchenko/panda/pickled_tiled_images_{LEVEL}_{N_TILES}_{IMAGE_SIZE}',\n",
    "        load_pickled_tiles=True,       \n",
    "        output_type='ordinal',\n",
    "        pseudo_labels_columns=[f'class_{x}' for x in range(5)]\n",
    "        )    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)  \n",
    "    holdout_loader = DataLoader(holdout_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)  \n",
    "    \n",
    "    loaders = collections.OrderedDict()\n",
    "    loaders[\"train\"] = train_loader\n",
    "    loaders[\"valid\"] = val_loader\n",
    "    loaders[\"holdout\"] = holdout_loader\n",
    "    losses = dict({\n",
    "        'loss_isup': criterion,\n",
    "    })\n",
    "    runner = SupervisedRunner(\n",
    "        input_key='features',\n",
    "        input_target_key=\"targets_isup_pseudolabels\",\n",
    "        output_key=\"logits_isup\"\n",
    "        )    \n",
    "    \n",
    "    callbacks = [\n",
    "        CriterionCallback(\n",
    "            input_key=\"targets_isup_pseudolabels\",\n",
    "            output_key=\"logits_isup\",\n",
    "            prefix=\"loss_isup\",\n",
    "            criterion_key='loss_isup',\n",
    "            multiplier=1.0\n",
    "        ),\n",
    "        QWKCallback(input_key=\"targets_isup\", \n",
    "                    output_key='logits_isup',\n",
    "                    qwk_name='ordinal'\n",
    "                    #qwk_name='simple',\n",
    "                   ),\n",
    "        MetricAggregationCallback(\n",
    "            prefix=\"loss\",\n",
    "            mode=\"weighted_sum\",\n",
    "            metrics={\n",
    "                \"loss_isup\": 1.0\n",
    "            }\n",
    "        ),\n",
    "        EarlyStoppingCallback(patience = PATIENCE, min_delta=1e-4),\n",
    "        CheckpointCallback(save_n_best = 5)    \n",
    "    ]    \n",
    "    \n",
    "    freeze(model)\n",
    "    optimizer = RAdam(model.parameters(), lr=INIT_LR)\n",
    "    optimizer = Lookahead(optimizer)\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=losses,\n",
    "        optimizer=optimizer,\n",
    "        callbacks=callbacks,\n",
    "        loaders=loaders,\n",
    "        logdir=LOG_DIR.format(fold_idx),\n",
    "        main_metric='loss',\n",
    "        num_epochs=N_FROZEN_ENCODER,\n",
    "        verbose=True,\n",
    "        minimize_metric=True,\n",
    "        fp16=True\n",
    "    )    \n",
    "    model.load_state_dict(torch.load(LOG_DIR.format(fold_idx)+'/checkpoints/best.pth')['model_state_dict'])\n",
    "    \n",
    "    \n",
    "    unfreeze(model)\n",
    "    optimizer = RAdam(model.parameters(), lr=INIT_LR/WARMUP_FACTOR)\n",
    "    optimizer = Lookahead(optimizer)\n",
    "    scheduler_cosine = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        N_EPOCHS-WARMUP_EPOCHS)\n",
    "    scheduler = GradualWarmupScheduler(\n",
    "        optimizer,\n",
    "        multiplier=WARMUP_FACTOR, \n",
    "        total_epoch=WARMUP_EPOCHS,\n",
    "        after_scheduler=scheduler_cosine)    \n",
    "    \n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=losses,\n",
    "        scheduler=scheduler,\n",
    "        optimizer=optimizer,\n",
    "        callbacks=callbacks,\n",
    "        loaders=loaders,\n",
    "        logdir=LOG_DIR.format(fold_idx),\n",
    "        main_metric='loss',\n",
    "        num_epochs=N_EPOCHS,\n",
    "        verbose=True,\n",
    "        minimize_metric=True,\n",
    "        fp16=True\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles36_level1_heavyHead_fold0_pseudolabeled\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "1/5 * Epoch (train):   0% 0/1692 [00:00<?, ?it/s]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "1/5 * Epoch (train):   0% 1/1692 [00:12<5:51:44, 12.48s/it, batch_qwk=0.286, loss=2.232, loss_isup=2.232]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "1/5 * Epoch (train):   0% 2/1692 [00:13<4:12:14,  8.96s/it, batch_qwk=-3.125e-01, loss=2.144, loss_isup=2.144]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "1/5 * Epoch (train): 100% 1692/1692 [07:21<00:00,  3.83it/s, batch_qwk=-6.667e-01, loss=0.526, loss_isup=0.526]\n",
      "1/5 * Epoch (valid):  29% 122/423 [00:22<00:36,  8.20it/s, batch_qwk=0.000e+00, loss=0.506, loss_isup=0.506] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/sklearn/metrics/_classification.py:604: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 * Epoch (valid): 100% 423/423 [00:59<00:00,  7.10it/s, batch_qwk=0.000e+00, loss=0.476, loss_isup=0.476] \n",
      "1/5 * Epoch (holdout): 100% 374/374 [00:54<00:00,  6.89it/s, batch_qwk=0.000e+00, loss=0.508, loss_isup=0.508] \n",
      "[2020-07-17 08:24:36,216] \n",
      "1/5 * Epoch 1 (_base): lr=0.0003 | momentum=0.9000\n",
      "1/5 * Epoch 1 (train): batch_qwk=0.0554 | loss=0.7746 | loss_isup=0.7746 | qwk=0.0411\n",
      "1/5 * Epoch 1 (valid): batch_qwk=nan | loss=0.5527 | loss_isup=0.5527 | qwk=0.0802\n",
      "1/5 * Epoch 1 (holdout): batch_qwk=0.0883 | loss=0.5476 | loss_isup=0.5476 | qwk=0.0902\n",
      "2/5 * Epoch (train):  22% 378/1692 [01:49<05:45,  3.80it/s, batch_qwk=-2.500e-01, loss=0.479, loss_isup=0.479]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2/5 * Epoch (train): 100% 1692/1692 [07:22<00:00,  3.83it/s, batch_qwk=-2.308e-01, loss=0.617, loss_isup=0.617]\n",
      "2/5 * Epoch (valid): 100% 423/423 [00:59<00:00,  7.06it/s, batch_qwk=-1.250e-01, loss=0.612, loss_isup=0.612]\n",
      "2/5 * Epoch (holdout): 100% 374/374 [00:53<00:00,  6.96it/s, batch_qwk=0.000e+00, loss=0.682, loss_isup=0.682] \n",
      "[2020-07-17 08:33:52,848] \n",
      "2/5 * Epoch 2 (_base): lr=0.0003 | momentum=0.9000\n",
      "2/5 * Epoch 2 (train): batch_qwk=0.1264 | loss=0.5571 | loss_isup=0.5571 | qwk=0.1182\n",
      "2/5 * Epoch 2 (valid): batch_qwk=0.2771 | loss=0.5443 | loss_isup=0.5443 | qwk=0.3848\n",
      "2/5 * Epoch 2 (holdout): batch_qwk=0.2676 | loss=0.5380 | loss_isup=0.5380 | qwk=0.3802\n",
      "3/5 * Epoch (train):  41% 695/1692 [03:11<04:21,  3.82it/s, batch_qwk=0.000e+00, loss=0.479, loss_isup=0.479] Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "3/5 * Epoch (train): 100% 1692/1692 [07:24<00:00,  3.80it/s, batch_qwk=0.250, loss=0.365, loss_isup=0.365]     \n",
      "3/5 * Epoch (valid): 100% 423/423 [01:00<00:00,  6.94it/s, batch_qwk=-1.250e-01, loss=0.539, loss_isup=0.539]\n",
      "3/5 * Epoch (holdout): 100% 374/374 [00:53<00:00,  6.97it/s, batch_qwk=0.000e+00, loss=0.615, loss_isup=0.615] \n",
      "[2020-07-17 08:43:15,279] \n",
      "3/5 * Epoch 3 (_base): lr=0.0003 | momentum=0.9000\n",
      "3/5 * Epoch 3 (train): batch_qwk=nan | loss=0.5397 | loss_isup=0.5397 | qwk=0.2000\n",
      "3/5 * Epoch 3 (valid): batch_qwk=nan | loss=0.5073 | loss_isup=0.5073 | qwk=0.3829\n",
      "3/5 * Epoch 3 (holdout): batch_qwk=0.2598 | loss=0.5009 | loss_isup=0.5009 | qwk=0.3688\n",
      "4/5 * Epoch (train):  68% 1145/1692 [05:04<02:15,  4.02it/s, batch_qwk=0.500, loss=0.559, loss_isup=0.559]     Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "4/5 * Epoch (train): 100% 1692/1692 [07:23<00:00,  3.82it/s, batch_qwk=0.000e+00, loss=0.606, loss_isup=0.606] \n",
      "4/5 * Epoch (valid): 100% 423/423 [01:00<00:00,  6.94it/s, batch_qwk=-1.200e-01, loss=0.521, loss_isup=0.521]\n",
      "4/5 * Epoch (holdout): 100% 374/374 [00:54<00:00,  6.87it/s, batch_qwk=0.000e+00, loss=0.607, loss_isup=0.607] \n",
      "[2020-07-17 08:52:35,865] \n",
      "4/5 * Epoch 4 (_base): lr=0.0003 | momentum=0.9000\n",
      "4/5 * Epoch 4 (train): batch_qwk=0.2414 | loss=0.5267 | loss_isup=0.5267 | qwk=0.2513\n",
      "4/5 * Epoch 4 (valid): batch_qwk=nan | loss=0.4858 | loss_isup=0.4858 | qwk=0.3928\n",
      "4/5 * Epoch 4 (holdout): batch_qwk=0.2825 | loss=0.4767 | loss_isup=0.4767 | qwk=0.3854\n",
      "5/5 * Epoch (train):  88% 1485/1692 [06:31<00:52,  3.96it/s, batch_qwk=0.294, loss=0.415, loss_isup=0.415]     Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "5/5 * Epoch (train): 100% 1692/1692 [07:23<00:00,  3.82it/s, batch_qwk=0.167, loss=0.516, loss_isup=0.516]     \n",
      "5/5 * Epoch (valid): 100% 423/423 [00:59<00:00,  7.09it/s, batch_qwk=-1.250e-01, loss=0.543, loss_isup=0.543]\n",
      "5/5 * Epoch (holdout): 100% 374/374 [00:56<00:00,  6.64it/s, batch_qwk=0.000e+00, loss=0.531, loss_isup=0.531] \n",
      "[2020-07-17 09:01:57,351] \n",
      "5/5 * Epoch 5 (_base): lr=0.0003 | momentum=0.9000\n",
      "5/5 * Epoch 5 (train): batch_qwk=0.2500 | loss=0.5204 | loss_isup=0.5204 | qwk=0.2792\n",
      "5/5 * Epoch 5 (valid): batch_qwk=nan | loss=0.4797 | loss_isup=0.4797 | qwk=0.4280\n",
      "5/5 * Epoch 5 (holdout): batch_qwk=0.2896 | loss=0.4709 | loss_isup=0.4709 | qwk=0.3997\n",
      "Top best models:\n",
      "/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles36_level1_heavyHead_fold0_pseudolabeled/checkpoints/train.5.pth\t0.4797\n",
      "/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles36_level1_heavyHead_fold0_pseudolabeled/checkpoints/train.4.pth\t0.4858\n",
      "/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles36_level1_heavyHead_fold0_pseudolabeled/checkpoints/train.3.pth\t0.5073\n",
      "/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles36_level1_heavyHead_fold0_pseudolabeled/checkpoints/train.2.pth\t0.5443\n",
      "/data/personal_folders/skolchenko/panda/logs/resnet34_size256_tiles36_level1_heavyHead_fold0_pseudolabeled/checkpoints/train.1.pth\t0.5527\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "1/100 * Epoch (train):   0% 0/1692 [00:00<?, ?it/s]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "1/100 * Epoch (train):   0% 5/1692 [00:15<1:41:08,  3.60s/it, batch_qwk=0.385, loss=0.426, loss_isup=0.426]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "1/100 * Epoch (train):   6% 96/1692 [00:44<08:05,  3.29it/s, batch_qwk=0.500, loss=0.405, loss_isup=0.405]      Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "1/100 * Epoch (train): 100% 1692/1692 [09:01<00:00,  3.12it/s, batch_qwk=-6.250e-01, loss=0.641, loss_isup=0.641]\n",
      "1/100 * Epoch (valid): 100% 423/423 [01:00<00:00,  7.00it/s, batch_qwk=-1.250e-01, loss=0.557, loss_isup=0.557]\n",
      "1/100 * Epoch (holdout): 100% 374/374 [00:54<00:00,  6.87it/s, batch_qwk=0.000e+00, loss=0.563, loss_isup=0.563] \n",
      "[2020-07-17 09:12:56,357] \n",
      "1/100 * Epoch 6 (_base): lr=6.000e-05 | momentum=0.9000\n",
      "1/100 * Epoch 6 (train): batch_qwk=0.2624 | loss=0.5099 | loss_isup=0.5099 | qwk=0.2780\n",
      "1/100 * Epoch 6 (valid): batch_qwk=nan | loss=0.4830 | loss_isup=0.4830 | qwk=0.4337\n",
      "1/100 * Epoch 6 (holdout): batch_qwk=0.2994 | loss=0.4736 | loss_isup=0.4736 | qwk=0.4083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skolchenko/.conda/envs/deeplearning/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:113: UserWarning:\n",
      "\n",
      "Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/100 * Epoch (train):  27% 452/1692 [02:36<06:26,  3.20it/s, batch_qwk=-2.500e-01, loss=0.402, loss_isup=0.402]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "2/100 * Epoch (train): 100% 1692/1692 [09:03<00:00,  3.11it/s, batch_qwk=1.000, loss=0.236, loss_isup=0.236]     \n",
      "2/100 * Epoch (valid): 100% 423/423 [01:00<00:00,  6.97it/s, batch_qwk=0.200, loss=0.348, loss_isup=0.348]     \n",
      "2/100 * Epoch (holdout): 100% 374/374 [00:55<00:00,  6.77it/s, batch_qwk=0.000e+00, loss=0.292, loss_isup=0.292] \n",
      "[2020-07-17 09:24:00,663] \n",
      "2/100 * Epoch 7 (_base): lr=0.0001 | momentum=0.9000\n",
      "2/100 * Epoch 7 (train): batch_qwk=nan | loss=0.4309 | loss_isup=0.4309 | qwk=0.5747\n",
      "2/100 * Epoch 7 (valid): batch_qwk=nan | loss=0.3679 | loss_isup=0.3679 | qwk=0.7007\n",
      "2/100 * Epoch 7 (holdout): batch_qwk=0.5769 | loss=0.3627 | loss_isup=0.3627 | qwk=0.6936\n",
      "3/100 * Epoch (train):  38% 638/1692 [03:33<05:27,  3.22it/s, batch_qwk=0.750, loss=0.346, loss_isup=0.346]     Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "3/100 * Epoch (train): 100% 1692/1692 [09:02<00:00,  3.12it/s, batch_qwk=0.737, loss=0.273, loss_isup=0.273]     \n",
      "3/100 * Epoch (valid): 100% 423/423 [01:00<00:00,  6.98it/s, batch_qwk=0.200, loss=0.278, loss_isup=0.278]     \n",
      "3/100 * Epoch (holdout): 100% 374/374 [00:54<00:00,  6.91it/s, batch_qwk=nan, loss=0.248, loss_isup=0.248]       \n",
      "[2020-07-17 09:35:02,126] \n",
      "3/100 * Epoch 8 (_base): lr=0.0002 | momentum=0.9000\n",
      "3/100 * Epoch 8 (train): batch_qwk=nan | loss=0.3815 | loss_isup=0.3815 | qwk=0.6790\n",
      "3/100 * Epoch 8 (valid): batch_qwk=nan | loss=0.2980 | loss_isup=0.2980 | qwk=0.8167\n",
      "3/100 * Epoch 8 (holdout): batch_qwk=nan | loss=0.2931 | loss_isup=0.2931 | qwk=0.8215\n",
      "4/100 * Epoch (train):  41% 692/1692 [03:50<05:22,  3.10it/s, batch_qwk=0.871, loss=0.381, loss_isup=0.381]     "
     ]
    }
   ],
   "source": [
    "train_fold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('deeplearning': conda)",
   "language": "python",
   "name": "python37564bitdeeplearningconda2f5dcc693383402099797ed40bd3951d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
